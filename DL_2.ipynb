{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Feed-forward neural networks with Keras and TensorFlow\n",
        "\n",
        "\n",
        "1.   Import the necessary packages\n",
        "2.   Load the training and testing data (MNIST/CIFAR10)\n",
        "3.   Define the network architecture using Keras\n",
        "4.   Train the model using SGD\n",
        "5.   Evaluate the network\n",
        "6.   Plot the training loss and accuracy"
      ],
      "metadata": {
        "id": "o1_g3NBH5h_V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjMIfEiL6kOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7b9cc6-89f9-4fd2-fbb0-addc7435df7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMGNO = 20000\n",
        "print(x_train[IMGNO])\n",
        "plt.imshow(x_train[IMGNO]);\n",
        "print(\"The label for image number\", IMGNO, \"is\", y_train[IMGNO])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YpXmeoH5BA02",
        "outputId": "263f257b-5560-46dc-df5e-aaa611115c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9\n",
            "   19  29 216 254 254 167   9   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  53 197\n",
            "  220 220 253 253 253 253 163   9   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  62 100 148 236 253\n",
            "  253 253 232 154 154 154 228 125   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  31 243 243 243 250 253 253 254 248\n",
            "  231 222  47   0   0   0   8   6   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 157 253 253 253 253 236 150 136  65\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 243 253 253 172 165  67   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  92 253 253 211  11   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 167 253 253  98   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  21 223 253 253 202 188 188 154 174 189 159\n",
            "   14   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 163 253 253 253 253 253 253 253 253 254 253\n",
            "  227 221 125   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 178 254 254 254 254 254 254 244 236 241 254\n",
            "  254 254 230  46   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 100 253 253 239 187 187 120  54  34  44  77\n",
            "  121 251 253 188   6   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  12 135  48  34   0   0   0   0   0   0   0\n",
            "    0 243 253 253  22   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   53 249 253 207  11   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  39 100 128   0   0   0   0   0   0   0   0\n",
            "  172 253 241 129   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  65 237 219  79   0   0   0   0   0   0  12 166\n",
            "  244 253 159   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 245 253 154   0   0   0   0   0   9  60 236 253\n",
            "  253 248  84   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 254 253 171  45  45  84 155 155 228 253 255 253\n",
            "  253 121   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 221 253 253 253 253 253 253 253 253 253 254 199\n",
            "   85  32   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  82  95 143  95 167 253 205 234  61  33  33  10\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "The label for image number 20000 is 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "x_train = x_train.reshape((x_train.shape[0], 28 * 28 * 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28 * 28 * 1))\n",
        "x_train = x_train.astype(\"float\") / 255.0\n",
        "x_test = x_test.astype(\"float\") / 255.0\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_test = lb.transform(y_test)\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"sigmoid\"))\n",
        "model.add(Dense(128, activation=\"sigmoid\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "sgd = SGD(0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "H = model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "\tepochs=100, batch_size=128)\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(x_test, batch_size=128)\n",
        "print(classification_report(y_test.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1),\n",
        "\ttarget_names=[str(x) for x in lb.classes_]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuLZ2CSJCdYr",
        "outputId": "5edb682b-a73d-47a2-8df3-b3fda778b00d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 11s 6ms/step - loss: 1.7883 - accuracy: 0.6026 - val_loss: 1.3371 - val_accuracy: 0.7706\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.0828 - accuracy: 0.8078 - val_loss: 0.8585 - val_accuracy: 0.8428\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.7506 - accuracy: 0.8548 - val_loss: 0.6353 - val_accuracy: 0.8737\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5826 - accuracy: 0.8794 - val_loss: 0.5126 - val_accuracy: 0.8880\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4835 - accuracy: 0.8923 - val_loss: 0.4378 - val_accuracy: 0.9002\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4203 - accuracy: 0.9024 - val_loss: 0.3875 - val_accuracy: 0.9060\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3765 - accuracy: 0.9082 - val_loss: 0.3546 - val_accuracy: 0.9097\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3454 - accuracy: 0.9131 - val_loss: 0.3299 - val_accuracy: 0.9143\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3200 - accuracy: 0.9178 - val_loss: 0.3088 - val_accuracy: 0.9209\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2998 - accuracy: 0.9219 - val_loss: 0.2901 - val_accuracy: 0.9236\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2834 - accuracy: 0.9261 - val_loss: 0.2786 - val_accuracy: 0.9272\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2688 - accuracy: 0.9294 - val_loss: 0.2676 - val_accuracy: 0.9265\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2567 - accuracy: 0.9319 - val_loss: 0.2596 - val_accuracy: 0.9298\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2463 - accuracy: 0.9338 - val_loss: 0.2488 - val_accuracy: 0.9326\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2360 - accuracy: 0.9373 - val_loss: 0.2392 - val_accuracy: 0.9353\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2264 - accuracy: 0.9395 - val_loss: 0.2341 - val_accuracy: 0.9348\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2176 - accuracy: 0.9420 - val_loss: 0.2268 - val_accuracy: 0.9365\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2102 - accuracy: 0.9441 - val_loss: 0.2215 - val_accuracy: 0.9382\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2035 - accuracy: 0.9463 - val_loss: 0.2150 - val_accuracy: 0.9402\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1972 - accuracy: 0.9472 - val_loss: 0.2114 - val_accuracy: 0.9411\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1908 - accuracy: 0.9493 - val_loss: 0.2057 - val_accuracy: 0.9424\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1854 - accuracy: 0.9510 - val_loss: 0.2006 - val_accuracy: 0.9443\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1794 - accuracy: 0.9522 - val_loss: 0.1998 - val_accuracy: 0.9444\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1751 - accuracy: 0.9540 - val_loss: 0.1959 - val_accuracy: 0.9448\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1702 - accuracy: 0.9550 - val_loss: 0.1911 - val_accuracy: 0.9455\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1643 - accuracy: 0.9563 - val_loss: 0.1878 - val_accuracy: 0.9468\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1598 - accuracy: 0.9575 - val_loss: 0.1852 - val_accuracy: 0.9470\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1557 - accuracy: 0.9590 - val_loss: 0.1808 - val_accuracy: 0.9491\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1516 - accuracy: 0.9597 - val_loss: 0.1802 - val_accuracy: 0.9478\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1487 - accuracy: 0.9607 - val_loss: 0.1772 - val_accuracy: 0.9484\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1446 - accuracy: 0.9625 - val_loss: 0.1740 - val_accuracy: 0.9489\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1407 - accuracy: 0.9634 - val_loss: 0.1719 - val_accuracy: 0.9504\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1367 - accuracy: 0.9644 - val_loss: 0.1695 - val_accuracy: 0.9517\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1346 - accuracy: 0.9654 - val_loss: 0.1683 - val_accuracy: 0.9503\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1306 - accuracy: 0.9659 - val_loss: 0.1681 - val_accuracy: 0.9524\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1277 - accuracy: 0.9668 - val_loss: 0.1665 - val_accuracy: 0.9514\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1251 - accuracy: 0.9677 - val_loss: 0.1640 - val_accuracy: 0.9524\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1225 - accuracy: 0.9687 - val_loss: 0.1604 - val_accuracy: 0.9535\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1195 - accuracy: 0.9691 - val_loss: 0.1599 - val_accuracy: 0.9537\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1173 - accuracy: 0.9701 - val_loss: 0.1587 - val_accuracy: 0.9531\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1151 - accuracy: 0.9707 - val_loss: 0.1585 - val_accuracy: 0.9541\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1125 - accuracy: 0.9712 - val_loss: 0.1587 - val_accuracy: 0.9539\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1101 - accuracy: 0.9721 - val_loss: 0.1563 - val_accuracy: 0.9544\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1074 - accuracy: 0.9729 - val_loss: 0.1533 - val_accuracy: 0.9547\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1052 - accuracy: 0.9738 - val_loss: 0.1537 - val_accuracy: 0.9549\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1025 - accuracy: 0.9748 - val_loss: 0.1527 - val_accuracy: 0.9550\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.9751 - val_loss: 0.1480 - val_accuracy: 0.9555\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0983 - accuracy: 0.9755 - val_loss: 0.1491 - val_accuracy: 0.9556\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0958 - accuracy: 0.9761 - val_loss: 0.1474 - val_accuracy: 0.9562\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0939 - accuracy: 0.9769 - val_loss: 0.1472 - val_accuracy: 0.9564\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0920 - accuracy: 0.9775 - val_loss: 0.1468 - val_accuracy: 0.9553\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0900 - accuracy: 0.9780 - val_loss: 0.1461 - val_accuracy: 0.9550\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0887 - accuracy: 0.9782 - val_loss: 0.1456 - val_accuracy: 0.9564\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0867 - accuracy: 0.9790 - val_loss: 0.1447 - val_accuracy: 0.9567\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0855 - accuracy: 0.9792 - val_loss: 0.1432 - val_accuracy: 0.9566\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0838 - accuracy: 0.9798 - val_loss: 0.1435 - val_accuracy: 0.9563\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0819 - accuracy: 0.9802 - val_loss: 0.1416 - val_accuracy: 0.9566\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0810 - accuracy: 0.9805 - val_loss: 0.1413 - val_accuracy: 0.9567\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0790 - accuracy: 0.9811 - val_loss: 0.1414 - val_accuracy: 0.9552\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0766 - accuracy: 0.9819 - val_loss: 0.1396 - val_accuracy: 0.9565\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0750 - accuracy: 0.9826 - val_loss: 0.1393 - val_accuracy: 0.9563\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0738 - accuracy: 0.9828 - val_loss: 0.1373 - val_accuracy: 0.9575\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9824 - val_loss: 0.1378 - val_accuracy: 0.9575\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0708 - accuracy: 0.9835 - val_loss: 0.1367 - val_accuracy: 0.9575\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0698 - accuracy: 0.9839 - val_loss: 0.1368 - val_accuracy: 0.9563\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0691 - accuracy: 0.9840 - val_loss: 0.1367 - val_accuracy: 0.9575\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0678 - accuracy: 0.9843 - val_loss: 0.1354 - val_accuracy: 0.9592\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0663 - accuracy: 0.9846 - val_loss: 0.1357 - val_accuracy: 0.9572\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0652 - accuracy: 0.9852 - val_loss: 0.1342 - val_accuracy: 0.9583\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0640 - accuracy: 0.9855 - val_loss: 0.1352 - val_accuracy: 0.9571\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0630 - accuracy: 0.9858 - val_loss: 0.1348 - val_accuracy: 0.9582\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0622 - accuracy: 0.9859 - val_loss: 0.1338 - val_accuracy: 0.9573\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9861 - val_loss: 0.1335 - val_accuracy: 0.9572\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0598 - accuracy: 0.9865 - val_loss: 0.1319 - val_accuracy: 0.9596\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.1328 - val_accuracy: 0.9585\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0579 - accuracy: 0.9870 - val_loss: 0.1316 - val_accuracy: 0.9590\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0570 - accuracy: 0.9870 - val_loss: 0.1321 - val_accuracy: 0.9578\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0559 - accuracy: 0.9870 - val_loss: 0.1316 - val_accuracy: 0.9598\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0552 - accuracy: 0.9873 - val_loss: 0.1323 - val_accuracy: 0.9600\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.9875 - val_loss: 0.1322 - val_accuracy: 0.9578\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0540 - accuracy: 0.9878 - val_loss: 0.1308 - val_accuracy: 0.9588\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0530 - accuracy: 0.9881 - val_loss: 0.1308 - val_accuracy: 0.9589\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0519 - accuracy: 0.9883 - val_loss: 0.1307 - val_accuracy: 0.9598\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0514 - accuracy: 0.9883 - val_loss: 0.1306 - val_accuracy: 0.9591\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0505 - accuracy: 0.9886 - val_loss: 0.1307 - val_accuracy: 0.9593\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9887 - val_loss: 0.1311 - val_accuracy: 0.9578\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0492 - accuracy: 0.9889 - val_loss: 0.1302 - val_accuracy: 0.9600\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0486 - accuracy: 0.9889 - val_loss: 0.1295 - val_accuracy: 0.9596\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0480 - accuracy: 0.9892 - val_loss: 0.1291 - val_accuracy: 0.9596\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0473 - accuracy: 0.9893 - val_loss: 0.1289 - val_accuracy: 0.9605\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0467 - accuracy: 0.9894 - val_loss: 0.1296 - val_accuracy: 0.9593\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0465 - accuracy: 0.9894 - val_loss: 0.1287 - val_accuracy: 0.9612\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0456 - accuracy: 0.9897 - val_loss: 0.1281 - val_accuracy: 0.9608\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0451 - accuracy: 0.9897 - val_loss: 0.1286 - val_accuracy: 0.9600\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0445 - accuracy: 0.9899 - val_loss: 0.1281 - val_accuracy: 0.9610\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0440 - accuracy: 0.9900 - val_loss: 0.1288 - val_accuracy: 0.9604\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0437 - accuracy: 0.9899 - val_loss: 0.1286 - val_accuracy: 0.9601\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0433 - accuracy: 0.9902 - val_loss: 0.1284 - val_accuracy: 0.9604\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0430 - accuracy: 0.9900 - val_loss: 0.1276 - val_accuracy: 0.9602\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0425 - accuracy: 0.9901 - val_loss: 0.1278 - val_accuracy: 0.9602\n",
            "[INFO] evaluating network...\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       980\n",
            "           1       0.98      0.99      0.98      1135\n",
            "           2       0.96      0.95      0.95      1032\n",
            "           3       0.94      0.96      0.95      1010\n",
            "           4       0.95      0.96      0.95       982\n",
            "           5       0.96      0.95      0.95       892\n",
            "           6       0.96      0.97      0.97       958\n",
            "           7       0.96      0.95      0.96      1028\n",
            "           8       0.96      0.95      0.95       974\n",
            "           9       0.95      0.94      0.94      1009\n",
            "\n",
            "    accuracy                           0.96     10000\n",
            "   macro avg       0.96      0.96      0.96     10000\n",
            "weighted avg       0.96      0.96      0.96     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "print(\"[INFO] loading CIFAR-10 data...\")\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_37PKJ0Mw0q",
        "outputId": "bb426a44-c1a8-4f78-a723-63753623fab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading CIFAR-10 data...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 5s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMGNO = 20000\n",
        "print(trainX[IMGNO])\n",
        "plt.imshow(trainX[IMGNO]);\n",
        "print(\"The label for image number\", IMGNO, \"is\", trainY[IMGNO])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pL0oUk4FSYVZ",
        "outputId": "657396b8-1be8-4b73-946b-bf8087745d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 26  23  32]\n",
            "  [ 17  14  25]\n",
            "  [ 13   9  24]\n",
            "  ...\n",
            "  [ 15  14  28]\n",
            "  [ 24  24  37]\n",
            "  [ 22  21  34]]\n",
            "\n",
            " [[ 20  17  26]\n",
            "  [ 13  10  22]\n",
            "  [ 13   9  24]\n",
            "  ...\n",
            "  [ 19  17  35]\n",
            "  [ 21  20  35]\n",
            "  [ 29  29  39]]\n",
            "\n",
            " [[ 14  11  20]\n",
            "  [ 13  10  21]\n",
            "  [ 13   9  23]\n",
            "  ...\n",
            "  [ 17  16  32]\n",
            "  [ 25  24  38]\n",
            "  [ 31  31  42]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 90 109 137]\n",
            "  [ 34  64  95]\n",
            "  [ 28  54  90]\n",
            "  ...\n",
            "  [ 23  20  37]\n",
            "  [ 16  13  30]\n",
            "  [  9   6  23]]\n",
            "\n",
            " [[ 79 105 141]\n",
            "  [ 58  96 139]\n",
            "  [ 32  68 110]\n",
            "  ...\n",
            "  [ 14  11  28]\n",
            "  [ 16  13  30]\n",
            "  [ 10   7  24]]\n",
            "\n",
            " [[128 157 196]\n",
            "  [ 58  93 149]\n",
            "  [ 25  60 106]\n",
            "  ...\n",
            "  [ 13  10  27]\n",
            "  [ 12   9  26]\n",
            "  [ 13  10  27]]]\n",
            "The label for image number 20000 is [8]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = trainX.astype(\"float\") / 255.0\n",
        "testX = testX.astype(\"float\") / 255.0\n",
        "trainX = trainX.reshape((trainX.shape[0], 3072))\n",
        "testX = testX.reshape((testX.shape[0], 3072))\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "print(trainY[0])\n",
        "print(trainX[0])\n",
        "# initialize the label names for the CIFAR-10 dataset\n",
        "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "\t\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko0snM75S3Jy",
        "outputId": "80a38eeb-36c7-4e73-fc0e-236b3dfe6aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 1 0 0 0]\n",
            "[0.23137255 0.24313725 0.24705882 ... 0.48235294 0.36078431 0.28235294]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), activation=\"relu\"))\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "XFqv-WhXWabK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] training network...\")\n",
        "sgd = SGD(0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
        "\tepochs=100, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRdn6j1HWfDn",
        "outputId": "f97451bd-86c0-4b87-d2f1-1daa7bf2ac71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 8s 4ms/step - loss: 1.8379 - accuracy: 0.3437 - val_loss: 1.7060 - val_accuracy: 0.4024\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6526 - accuracy: 0.4158 - val_loss: 1.6143 - val_accuracy: 0.4370\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5740 - accuracy: 0.4420 - val_loss: 1.5975 - val_accuracy: 0.4327\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.5137 - accuracy: 0.4652 - val_loss: 1.5208 - val_accuracy: 0.4663\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4671 - accuracy: 0.4812 - val_loss: 1.4943 - val_accuracy: 0.4689\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4249 - accuracy: 0.4965 - val_loss: 1.4598 - val_accuracy: 0.4872\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3892 - accuracy: 0.5106 - val_loss: 1.4155 - val_accuracy: 0.4978\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3574 - accuracy: 0.5218 - val_loss: 1.4589 - val_accuracy: 0.4791\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3254 - accuracy: 0.5344 - val_loss: 1.4402 - val_accuracy: 0.4856\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2965 - accuracy: 0.5434 - val_loss: 1.5498 - val_accuracy: 0.4572\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2707 - accuracy: 0.5540 - val_loss: 1.5013 - val_accuracy: 0.4646\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2443 - accuracy: 0.5619 - val_loss: 1.4060 - val_accuracy: 0.4872\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2206 - accuracy: 0.5707 - val_loss: 1.3296 - val_accuracy: 0.5349\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1968 - accuracy: 0.5806 - val_loss: 1.4680 - val_accuracy: 0.4878\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1731 - accuracy: 0.5888 - val_loss: 1.3565 - val_accuracy: 0.5243\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1464 - accuracy: 0.5980 - val_loss: 1.3551 - val_accuracy: 0.5206\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1293 - accuracy: 0.6053 - val_loss: 1.3779 - val_accuracy: 0.5235\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1042 - accuracy: 0.6135 - val_loss: 1.3629 - val_accuracy: 0.5247\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0851 - accuracy: 0.6203 - val_loss: 1.3361 - val_accuracy: 0.5307\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0607 - accuracy: 0.6273 - val_loss: 1.3686 - val_accuracy: 0.5201\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.0423 - accuracy: 0.6356 - val_loss: 1.3665 - val_accuracy: 0.5216\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0202 - accuracy: 0.6442 - val_loss: 1.3069 - val_accuracy: 0.5402\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9985 - accuracy: 0.6500 - val_loss: 1.3510 - val_accuracy: 0.5230\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9812 - accuracy: 0.6566 - val_loss: 1.3140 - val_accuracy: 0.5415\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9553 - accuracy: 0.6675 - val_loss: 1.3942 - val_accuracy: 0.5222\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9380 - accuracy: 0.6739 - val_loss: 1.2903 - val_accuracy: 0.5513\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9148 - accuracy: 0.6804 - val_loss: 1.3021 - val_accuracy: 0.5510\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8942 - accuracy: 0.6889 - val_loss: 1.3618 - val_accuracy: 0.5373\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8715 - accuracy: 0.6977 - val_loss: 1.3538 - val_accuracy: 0.5387\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8519 - accuracy: 0.7033 - val_loss: 1.4420 - val_accuracy: 0.5184\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8348 - accuracy: 0.7090 - val_loss: 1.4762 - val_accuracy: 0.5154\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8126 - accuracy: 0.7202 - val_loss: 1.3533 - val_accuracy: 0.5542\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7922 - accuracy: 0.7247 - val_loss: 1.3817 - val_accuracy: 0.5333\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7704 - accuracy: 0.7352 - val_loss: 1.3986 - val_accuracy: 0.5296\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7498 - accuracy: 0.7412 - val_loss: 1.5109 - val_accuracy: 0.5151\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7287 - accuracy: 0.7502 - val_loss: 1.4362 - val_accuracy: 0.5401\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7071 - accuracy: 0.7572 - val_loss: 1.4345 - val_accuracy: 0.5342\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6868 - accuracy: 0.7649 - val_loss: 1.6490 - val_accuracy: 0.4903\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6690 - accuracy: 0.7715 - val_loss: 1.4222 - val_accuracy: 0.5442\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6492 - accuracy: 0.7780 - val_loss: 1.4295 - val_accuracy: 0.5435\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6304 - accuracy: 0.7847 - val_loss: 1.4951 - val_accuracy: 0.5262\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6096 - accuracy: 0.7918 - val_loss: 1.4950 - val_accuracy: 0.5366\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5884 - accuracy: 0.8004 - val_loss: 1.5047 - val_accuracy: 0.5370\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5747 - accuracy: 0.8047 - val_loss: 1.4882 - val_accuracy: 0.5438\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5531 - accuracy: 0.8115 - val_loss: 1.5468 - val_accuracy: 0.5375\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5385 - accuracy: 0.8166 - val_loss: 1.5254 - val_accuracy: 0.5452\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5172 - accuracy: 0.8255 - val_loss: 1.5317 - val_accuracy: 0.5463\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4980 - accuracy: 0.8347 - val_loss: 1.4967 - val_accuracy: 0.5527\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4806 - accuracy: 0.8384 - val_loss: 1.5501 - val_accuracy: 0.5507\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4649 - accuracy: 0.8451 - val_loss: 1.7347 - val_accuracy: 0.5126\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4473 - accuracy: 0.8507 - val_loss: 1.6150 - val_accuracy: 0.5451\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4306 - accuracy: 0.8587 - val_loss: 1.6226 - val_accuracy: 0.5381\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4126 - accuracy: 0.8639 - val_loss: 1.6302 - val_accuracy: 0.5503\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3979 - accuracy: 0.8689 - val_loss: 1.6327 - val_accuracy: 0.5460\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3783 - accuracy: 0.8760 - val_loss: 2.0444 - val_accuracy: 0.4851\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3624 - accuracy: 0.8835 - val_loss: 1.8139 - val_accuracy: 0.5189\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3495 - accuracy: 0.8862 - val_loss: 1.6638 - val_accuracy: 0.5521\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3316 - accuracy: 0.8939 - val_loss: 1.6595 - val_accuracy: 0.5516\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3202 - accuracy: 0.8977 - val_loss: 1.7710 - val_accuracy: 0.5392\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3041 - accuracy: 0.9043 - val_loss: 1.7534 - val_accuracy: 0.5410\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2907 - accuracy: 0.9088 - val_loss: 1.9204 - val_accuracy: 0.5150\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2760 - accuracy: 0.9155 - val_loss: 1.9264 - val_accuracy: 0.5282\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2666 - accuracy: 0.9176 - val_loss: 2.0324 - val_accuracy: 0.5274\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2575 - accuracy: 0.9199 - val_loss: 1.7772 - val_accuracy: 0.5520\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2404 - accuracy: 0.9279 - val_loss: 1.9067 - val_accuracy: 0.5407\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2289 - accuracy: 0.9329 - val_loss: 2.1492 - val_accuracy: 0.5194\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2237 - accuracy: 0.9324 - val_loss: 1.7920 - val_accuracy: 0.5641\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2048 - accuracy: 0.9406 - val_loss: 1.8152 - val_accuracy: 0.5538\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1960 - accuracy: 0.9445 - val_loss: 1.8029 - val_accuracy: 0.5638\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1833 - accuracy: 0.9483 - val_loss: 2.0521 - val_accuracy: 0.5322\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1784 - accuracy: 0.9489 - val_loss: 1.9351 - val_accuracy: 0.5523\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1664 - accuracy: 0.9539 - val_loss: 1.8984 - val_accuracy: 0.5655\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1578 - accuracy: 0.9567 - val_loss: 1.8569 - val_accuracy: 0.5632\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1492 - accuracy: 0.9602 - val_loss: 1.9813 - val_accuracy: 0.5571\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1358 - accuracy: 0.9649 - val_loss: 2.0007 - val_accuracy: 0.5501\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1302 - accuracy: 0.9662 - val_loss: 2.1213 - val_accuracy: 0.5358\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1289 - accuracy: 0.9658 - val_loss: 2.2164 - val_accuracy: 0.5405\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1164 - accuracy: 0.9710 - val_loss: 2.1361 - val_accuracy: 0.5438\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1149 - accuracy: 0.9706 - val_loss: 2.0183 - val_accuracy: 0.5579\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1029 - accuracy: 0.9757 - val_loss: 2.0366 - val_accuracy: 0.5588\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0965 - accuracy: 0.9781 - val_loss: 2.0325 - val_accuracy: 0.5671\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0843 - accuracy: 0.9827 - val_loss: 2.0594 - val_accuracy: 0.5588\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0810 - accuracy: 0.9828 - val_loss: 2.2184 - val_accuracy: 0.5466\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0819 - accuracy: 0.9821 - val_loss: 2.0976 - val_accuracy: 0.5635\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0739 - accuracy: 0.9846 - val_loss: 2.0962 - val_accuracy: 0.5690\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0657 - accuracy: 0.9877 - val_loss: 2.1353 - val_accuracy: 0.5645\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0639 - accuracy: 0.9877 - val_loss: 2.2208 - val_accuracy: 0.5515\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0597 - accuracy: 0.9888 - val_loss: 2.3276 - val_accuracy: 0.5430\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0552 - accuracy: 0.9899 - val_loss: 2.1468 - val_accuracy: 0.5664\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0510 - accuracy: 0.9914 - val_loss: 2.2857 - val_accuracy: 0.5523\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0489 - accuracy: 0.9919 - val_loss: 2.2604 - val_accuracy: 0.5559\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0447 - accuracy: 0.9927 - val_loss: 2.6768 - val_accuracy: 0.5272\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0449 - accuracy: 0.9927 - val_loss: 2.2769 - val_accuracy: 0.5677\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0366 - accuracy: 0.9951 - val_loss: 2.2423 - val_accuracy: 0.5613\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0371 - accuracy: 0.9949 - val_loss: 2.2525 - val_accuracy: 0.5655\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0326 - accuracy: 0.9962 - val_loss: 2.3512 - val_accuracy: 0.5607\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0314 - accuracy: 0.9961 - val_loss: 2.3380 - val_accuracy: 0.5632\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0299 - accuracy: 0.9965 - val_loss: 2.2748 - val_accuracy: 0.5682\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0282 - accuracy: 0.9966 - val_loss: 2.2773 - val_accuracy: 0.5684\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0257 - accuracy: 0.9973 - val_loss: 2.3139 - val_accuracy: 0.5619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=labelNames))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSi7miK0s17C",
        "outputId": "e5f9948e-d2fc-4c18-e3c9-bafce047ee99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.64      0.62      0.63      1000\n",
            "  automobile       0.66      0.67      0.67      1000\n",
            "        bird       0.43      0.52      0.47      1000\n",
            "         cat       0.37      0.42      0.39      1000\n",
            "        deer       0.50      0.46      0.48      1000\n",
            "         dog       0.49      0.41      0.45      1000\n",
            "        frog       0.68      0.58      0.63      1000\n",
            "       horse       0.60      0.65      0.62      1000\n",
            "        ship       0.70      0.68      0.69      1000\n",
            "       truck       0.61      0.60      0.61      1000\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.57      0.56      0.56     10000\n",
            "weighted avg       0.57      0.56      0.56     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}